`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7))
View(self_report_data)
IA_AMP_cleaned <- IA_AMP_df %>%
# reshape influence variable
mutate(influenced = as.numeric(as.character(lead(correct)))) %>%
# keep only test blocks and ratings trials
filter(!str_detect(trialcode, "intention_check"),
blockcode == "test") %>%
# mutate some vars
mutate(prime_type = ifelse(trialcode %in% c("prime_obama", "prime_positive"), "prime_type_A", "prime_type_B"),
subject = as.character(subject),
rating = as.numeric(as.character(correct))) %>%
# exclude participants without the right number of AMP trials
group_by(subject) %>%
filter(n() == 120) %>%
ungroup() %>%
select(subject, prime_type, rating, influenced) %>%
# exclude those who didn't have the right number of trials on the screener
mutate(subject = as.character(subject))
# score amp effect
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect) %>%
mutate(IA_AMP_effect_positive_negative = round(prime_type_A - prime_type_B, 2)) %>%
select(subject, IA_AMP_effect_positive_negative)
# score influence rates
IA_AMP_influence_rate <- IA_AMP_cleaned %>%
group_by(subject) %>%
summarize(influence_rate = round(mean(influenced), 2)) %>%
ungroup()
IA_AMP_data <- IA_AMP_effect %>%
full_join(IA_AMP_influence_rate, by = "subject")
complete_demographics_data <- demographics_data %>%
na.omit() %>%
distinct(subject)
complete_self_report_data <- self_report_data %>%
na.omit() %>%
distinct(subject)
complete_IA_AMP_data <- IA_AMP_data %>%
na.omit() %>%
distinct(subject)
complete_data <- complete_demographics_data %>%
semi_join(complete_self_report_data, by = "subject") %>%
semi_join(complete_IA_AMP_data, by = "subject") %>%
mutate(complete_data = TRUE)
# combine
processed_data <- demographics_data %>%
full_join(IA_AMP_data, by = "subject") %>%
full_join(self_report_data, by = "subject") %>%
full_join(complete_data, by = "subject") %>%
mutate(complete_data = ifelse(is.na(complete_data), FALSE, complete_data))
# long format AMP data
trial_level_ia_amp_data <- processed_data %>%
right_join(IA_AMP_cleaned, by = "subject") %>%
select(subject, prime_type, rating, influenced, self_exclusion_1, complete_data)
# write to disk
write_csv(processed_data, "processed/processed_data.csv")
write_csv(trial_level_ia_amp_data, "processed/trial_level_ia_amp_positive_negative_data.csv")
# dependencies
library(tidyverse)
library(lme4)
library(sjPlot)
library(effects)
library(DescTools)
library(Rmisc)
library(effsize)
library(psych)
library(broom)
library(kableExtra)
# devtools::install_github("ianhussey/timesavers")
library(timesavers)  # for round_df()
# functions
## Logistic model performance: probability of superiority
ruscios_A <- function(variable, group, data, value1 = 1, value2 = 0) {
# Ensure data is a data frame (e.g., not a tbl_data)
data <- as.data.frame(data)
# Select the observations for group 1
x <- data[data[[group]] == value1, variable]
# Select the observations for group 2
y <- data[data[[group]] == value2, variable]
# Matrix with difference between XY for all pairs (Guillaume Rousselet's suggestion)
m <- outer(x, y, FUN = "-")
# Convert to booleans; count ties as half true.
m <- ifelse(m == 0, 0.5, m > 0)
# Return proportion of TRUEs
ruscios_A <- round(mean(m), 3)
return(as.numeric(ruscios_A))
}
# # version with CIs - computationally intensive
# ruscios_A_boot <- function(data, variable, group, value1 = 1, value2 = 0, B = 1000) {
#   require(tidyverse)
#   require(broom)
#   ruscios_A_results <- data %>%
#     ruscios_A(variable = variable,
#               group = group,
#               value1 = value1,
#               value2 = value2,
#               data = .)
#
#   ruscios_A_boot_results <- data %>%
#     broom::bootstrap(B) %>%
#     do(broom::tidy(ruscios_A(variable = variable,
#                              group = group,
#                              value1 = value1,
#                              value2 = value2,
#                              data = .))) %>%
#     ungroup() %>%
#     dplyr::summarize(AUC_ci_lwr = round(quantile(x, 0.025, na.rm = TRUE), 3),
#                      AUC_ci_upr = round(quantile(x, 0.975, na.rm = TRUE), 3)) %>%
#     mutate(AUC_estimate = ruscios_A_results)
#
#   return(ruscios_A_boot_results)
# }
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv") %>%
mutate(response = ifelse(response == "none" | response == "Never", 1,
ifelse(response == "a few" | response == "Very rarely", 2,
ifelse(response == "less than half" | response == "Somewhat rarely", 3,
ifelse(response == "about half" | response == "Sometimes", 4,
ifelse(response == "more than half", 5,
ifelse(response == "most", 6,
ifelse(response == "all", 7, response))))))))
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
fit_h3 <- lm(IA_AMP_effect_positive_negative ~ influence_general + influence_rate,
data = task_level_data_exclusions)
task_level_data_exclusions %>%
distinct(influence_general)
# plot
plot_model(fit_h3, type = "pred", terms = c("influence_rate"))
plot_model(fit_h3, type = "pred", terms = c("influence_general"))
# results table
tab_model(fit_h3, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# model performance
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$h3_predicted_probability <- predict(fit_h3, type = "response")
# model performance
# add model predictions back to the original data frame
task_level_data_exclusions$h3_predicted_probability <- predict(fit_h3, type = "response")
View(trial_level_ia_amp_data_exclusions)
View(task_level_data_exclusions)
# predicted probability
h3_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "h3_predicted_probability",
group = "rating")
h3_pp
# model
fit_h2 <- lm(influence_rate ~ influence_general, data = task_level_data_exclusions)
# Plot
ggplot(data = subject_level_df, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# model
fit_h2 <- lm(influence_rate ~ influence_general, data = task_level_data_exclusions)
# Plot
ggplot(data = task_level_data_exclusions, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# results table
tab_model(fit_h2, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# add model predictions back to the original data frame
task_level_data_exclusions$h2_predicted_probability <- predict(model_h2, type = "response")
# add model predictions back to the original data frame
task_level_data_exclusions$h2_predicted_probability <- predict(fit_h2, type = "response")
# predicted probability
h2_pp <- ruscios_A(data = task_level_data_exclusions,
variable = "h2_predicted_probability",
group = "rating")
h2_pp
View(task_level_data_exclusions)
# results table
tab_model(fit_h2, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# model
fit_h3 <- lm(IA_AMP_effect_positive_negative ~ influence_general + influence_rate,
data = task_level_data_exclusions)
# plot
plot_model(fit_h3, type = "pred", terms = c("influence_rate"))
plot_model(fit_h3, type = "pred", terms = c("influence_general"))
# results table
tab_model(fit_h3, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# model
fit_h2 <- lm(influence_rate ~ influence_general, data = task_level_data_exclusions)
# Plot
ggplot(data = task_level_data_exclusions, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# results table
tab_model(fit_h2, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# Plot
ggplot(data = task_level_data_exclusions, aes(x = influence_general, y = influence_rate)) +
geom_jitter(alpha = 0.3) +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# model
fit_h1b <- lm(IA_AMP_effect_positive_negative ~ influence_rate,
data = task_level_data_exclusions)
# plot
ggplot(task_level_data_exclusions, aes(influence_rate, IA_AMP_effect_positive_negative)) +
geom_jitter(alpha = 0.3) +
geom_rug(position = "jitter") +
geom_smooth(method = lm) +
labs(title = "Proportion of influenced trials and IA-AMP effect",
x = "Proportion of influenced trials",
y = "IA-AMP effect") +
theme_classic()
# results table
tab_model(fit_h1b, emph.p = FALSE, ci.hyphen = ", ")
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$h1a_predicted_probability <- predict(model_h1a, type = "response")
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# plot
plot_model(model_h1a, type = "pred", terms = c("influenced", "prime_type"))
# results table
tab_model(model_h1a, emph.p = FALSE, ci.hyphen = ", ")
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$h1a_predicted_probability <- predict(model_h1a, type = "response")
# predicted probability
h1a_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "h1a_predicted_probability",
group = "rating")
# fit model
model_m1 <- glmer(rating ~ prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# plot
plot_model(model_m1, type = "pred", terms = c("prime_type"))
# results table
tab_model(model_m1, emph.p = FALSE, ci.hyphen = ", ")
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$m1_predicted_probability <- predict(model_m1, type = "response")
# predicted probability
m1_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "m1_predicted_probability",
group = "correct")
m1_pp
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$m1_predicted_probability <- predict(model_m1, type = "response")
# predicted probability
m1_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "m1_predicted_probability",
group = "response")
m1_pp
# fit model
model_m1 <- glmer(rating ~ prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$m1_predicted_probability <- predict(model_m1, type = "response")
# predicted probability
m1_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "m1_predicted_probability",
group = "response")
m1_pp
# results table
tab_model(model_m1, emph.p = FALSE, ci.hyphen = ", ")
# results table
tab_model(model_m1, emph.p = FALSE, ci.hyphen = ", ")
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$m1_predicted_probability <- predict(model_m1, type = "response")
View(trial_level_ia_amp_data_exclusions)
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# fit model
model_m1 <- glmer(rating ~ prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$m1_predicted_probability <- predict(model_m1, type = "response")
# predicted probability
m1_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "m1_predicted_probability",
group = "rating")
# functions
## Logistic model performance: probability of superiority
ruscios_A <- function(variable, group, data, value1 = 1, value2 = 0) {
# Ensure data is a data frame (e.g., not a tbl_data)
data <- as.data.frame(data)
# Select the observations for group 1
x <- data[data[[group]] == value1, variable]
# Select the observations for group 2
y <- data[data[[group]] == value2, variable]
# Matrix with difference between XY for all pairs (Guillaume Rousselet's suggestion)
m <- outer(x, y, FUN = "-")
# Convert to booleans; count ties as half true.
m <- ifelse(m == 0, 0.5, m > 0)
# Return proportion of TRUEs
ruscios_A <- round(mean(m), 3)
return(as.numeric(ruscios_A))
}
# predicted probability
m1_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "m1_predicted_probability",
group = "rating")
# get data
demographics_df <- read.csv("raw/demographics.csv")
IA_AMP_df       <- read.csv("raw/modified_intentionality_amp.csv")
AMP_df          <- read.csv("raw/standard_amp.csv")
questions_df    <- read.csv("raw/post_questions.csv")
# match Prolific IDs to subject numbers (for payment processing)
prolificid_df <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode == "ProlificCode") %>%
dplyr::select(subject, response)
demographics_data <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode != "ProlificCode") %>%
select(subject, trialcode, response) %>%
spread(trialcode, response) %>%
mutate(subject = as.character(subject))
allowed_response_options <- c("none", "a few", "less than half", "about half", "more than half", "most", "all")
self_report_data <- questions_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
select(subject, trialcode, response) %>%
group_by(subject) %>%
spread(trialcode, response) %>%
ungroup %>%
mutate(subject = as.character(subject)) %>%
# some pilot data that used alternative reponse options made it into the data. exclude this.
mutate(awareness = ifelse(!(influence_general %in% allowed_response_options), NA, as.character(awareness)),
influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, as.character(influence_general)),
intentionality    = ifelse(!(intentionality %in% allowed_response_options), NA, as.character(intentionality)),
unintentionality  = ifelse(!(unintentionality %in% allowed_response_options), NA, as.character(unintentionality)),
# recode likert from string to integer
awareness = dplyr::recode(as.character(awareness),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
influence_general = dplyr::recode(as.character(influence_general),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
intentionality = dplyr::recode(as.character(intentionality),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
unintentionality = dplyr::recode(as.character(unintentionality),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
party = ifelse(politics %in% c("a little republican", "somewhat republican", "very republican"), "republican",
ifelse(politics %in% c("a little democratic", "somewhat democratic", "very democratic"), "democrat",
"neither/moderate")))
View(self_report_data)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# dependencies
library(tidyverse)
# get data
demographics_df <- read.csv("raw/demographics.csv")
IA_AMP_df       <- read.csv("raw/modified_intentionality_amp.csv")
AMP_df          <- read.csv("raw/standard_amp.csv")
questions_df    <- read.csv("raw/post_questions.csv")
# match Prolific IDs to subject numbers (for payment processing)
prolificid_df <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode == "ProlificCode") %>%
dplyr::select(subject, response)
demographics_data <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode != "ProlificCode") %>%
select(subject, trialcode, response) %>%
spread(trialcode, response) %>%
mutate(subject = as.character(subject))
allowed_response_options <- c("none", "a few", "less than half", "about half", "more than half", "most", "all")
self_report_data <- questions_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
select(subject, trialcode, response) %>%
group_by(subject) %>%
spread(trialcode, response) %>%
ungroup %>%
mutate(subject = as.character(subject)) %>%
# some pilot data that used alternative reponse options made it into the data. exclude this.
mutate(awareness = ifelse(!(influence_general %in% allowed_response_options), NA, as.character(awareness)),
influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, as.character(influence_general)),
intentionality    = ifelse(!(intentionality %in% allowed_response_options), NA, as.character(intentionality)),
unintentionality  = ifelse(!(unintentionality %in% allowed_response_options), NA, as.character(unintentionality)),
# recode likert from string to integer
awareness = dplyr::recode(as.character(awareness),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
influence_general = dplyr::recode(as.character(influence_general),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
intentionality = dplyr::recode(as.character(intentionality),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7),
unintentionality = dplyr::recode(as.character(unintentionality),
`none`           = 1,
`a few`          = 2,
`less than half` = 3,
`about half`     = 4,
`more than half` = 5,
`most`           = 6,
`all`            = 7))
AMP_cleaned <- AMP_df %>%
# keep only test blocks and ratings trials
filter(blockcode == "test") %>%
# mutate some vars
mutate(prime_type = ifelse(trialcode %in% c("prime_obama", "prime_positive"), "prime_type_A", "prime_type_B"),
subject = as.character(subject),
rating = as.numeric(as.character(correct))) %>%
# exclude participants without the right number of AMP trials
group_by(subject) %>%
filter(n() == 72) %>%
ungroup() %>%
select(subject, prime_type, rating) %>%
# exclude those who didn't have the right number of trials on the screener
mutate(subject = as.character(subject))
# score amp effect
AMP_data <- AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect) %>%
mutate(AMP_effect_positive_negative = round(prime_type_A - prime_type_B, 2)) %>%
select(subject, AMP_effect_positive_negative)
# combine
processed_data <- demographics_data %>%
full_join(IA_AMP_data, by = "subject") %>%
full_join(self_report_data, by = "subject") %>%
full_join(complete_data, by = "subject") %>%
mutate(complete_data = ifelse(is.na(complete_data), FALSE, complete_data))
AMP_cleaned <- AMP_df %>%
# keep only test blocks and ratings trials
filter(blockcode == "test") %>%
# mutate some vars
mutate(prime_type = ifelse(trialcode %in% c("prime_obama", "prime_positive"), "prime_type_A", "prime_type_B"),
subject = as.character(subject),
rating = as.numeric(as.character(correct))) %>%
# exclude participants without the right number of AMP trials
group_by(subject) %>%
filter(n() == 72) %>%
ungroup() %>%
select(subject, prime_type, rating) %>%
# exclude those who didn't have the right number of trials on the screener
mutate(subject = as.character(subject))
# score amp effect
AMP_data <- AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect) %>%
mutate(AMP_effect_positive_negative = round(prime_type_A - prime_type_B, 2)) %>%
select(subject, AMP_effect_positive_negative)
