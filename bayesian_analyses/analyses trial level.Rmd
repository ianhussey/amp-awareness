---
title: "Bayesian analyses of the role of conscious influence of the prime in the AMP effect"
subtitle: "Using posteriors as priors"
author: "Ian Hussey^[Ghent University. Email: ian.hussey@ugent.be]"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    number_sections: no
    theme: flatly
    toc: yes
    toc_float: yes
---

NB DOESN'T MODEL ABSOLUTE AMP EFFECTS WHEREAS THE PARTICIPANT LEVEL ANALYSIS DOES

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      cache = TRUE)
```

```{r}

# set seed
set.seed(42)

# disable scientific notation
options(scipen = 999) 

# options
options(knitr.table.format = "html")  # comment out if knitting to pdf

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(plotrix)  # for std.error
library(brms)
library(parallel)
library(sjPlot)
library(sjstats)
library(patchwork)

# rounds all numerics in a df
round_df <- function(df, digits) {
  nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
  df[,nums] <- round(df[,nums], digits = digits)
  (df)
}

# get data
exp_1_ia_amp_trial_level_data <- read.csv("../experiment 1/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(Experiment = 1,
         influenced = recode(influenced,
                             `0` = "no",
                             `1` = "yes")) %>%
  filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)

exp_2_ia_amp_trial_level_data <- read.csv("../experiment 2/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(Experiment = 2,
         influenced = recode(influenced,
                             `0` = "no",
                             `1` = "yes")) %>%
  filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)

exp_3_ia_amp_trial_level_data <- read.csv("../experiment 3/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(Experiment = 3,
         influenced = recode(influenced,
                             `0` = "no",
                             `1` = "yes")) %>%
  filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)

# exp_4_ia_amp_trial_level_data <- read.csv("../experiment 4/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
#  filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)


combined_data <- rbind(exp_1_ia_amp_trial_level_data,
                       exp_2_ia_amp_trial_level_data, 
                       exp_3_ia_amp_trial_level_data) %>%
  mutate(Experiment = as.factor(Experiment))

```


```{r}

# # plot
# ggplot(combined_data, aes(influence_rate, 
#                           absolute_int_amp_effect, 
#                           color = Experiment, 
#                           group = Experiment)) + 
#   geom_point(alpha = 0.3) +
#   geom_rug(position = "jitter") +
#   geom_smooth(method = lm) +
#   labs(x = "Proportion of influenced trials", 
#        y = "Absolute AMP effect") +
#   theme_classic() +
#   ylim(0, 1) +
#   scale_colour_viridis_d(end = 0.8) +
#   scale_fill_viridis_d(end = 0.8)

```

# Experiment 1

## Weak, non-informative prior

### Fit model

```{r}

# model generic setup
iterations    <- 2000
chains        <- 4
sample_prior  <- TRUE  # to optionally calculate Savage Dickey-BF
cores         <- detectCores()
control       <- list(adapt_delta = 0.99)
model_formula <- rating ~ influenced * prime_type + (1 | subject)
model_family  <- bernoulli(link = "logit")

# # check what parameteris require priors
# get_prior(formula = model_formula,
#           family  = model_family,
#           data    = data)

# model specific setup
data          <- exp_1_ia_amp_trial_level_data
prior         <- c(set_prior("normal(0, 1)"))  # weakly informative prior used on all parameters, see https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
model_path    <- "models/fit_1_weak_prior_trial_level_data"

# fit model
fit_1 <- brm(formula      = model_formula,
             family       = model_family,
             data         = data,
             prior        = prior,
             iter         = iterations,
             chains       = chains,
             sample_prior = sample_prior,
             cores        = cores,
             control      = control,
             file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_1, nsamples = 10) 

plot(fit_1, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

# Region of Practical Equivalence set to % of posterior standardized beta values within the range < .1 and > .1. That is, less than small effect size using Cohen's guidelines for R values. If > 95% of posterior is within this range, parameter can be said to be practically zero (i.e., evidence for null effect). Another option is to use Bayes Factors (below). ROPE on the posterior is less sensitive to the prior, but also usually requires greater N to estimate the parameter well enough to make such a conclusion.   
ROPE_data <- rope(fit_1, rope = c(-0.1, 0.1)) %>%  
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_1)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  dplyr::rename(`Std. Beta` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_1,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_1), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
H1_sav_dic         <- fit_1 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B = 0", alpha = .05)  

# p_h1 <- plot(H1_sav_dic, plot = FALSE, theme = theme_get())[[1]]  
# p_h1 + 
#   xlim(-3, 3) +
#   geom_vline(xintercept = H1_sav_dic$hypothesis$Estimate) +
#   theme_minimal()
plot(H1_sav_dic)

# Posterior evidence ratio (Bayesian p value)
H1_post_evid_ratio <- fit_1 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/H1_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(H1_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.

# Experiment 2

## Weak, non-informative prior

*Needs work*

### Fit model

```{r}

# model specific setup
data          <- exp_2_ia_amp_trial_level_data
prior         <- c(set_prior("normal(0, 1)"))  # weakly informative prior used on all parameters, see https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
model_path    <- "models/fit_2_weak_prior_trial_level_data"

# fit model
fit_2_weak_prior <- brm(formula      = model_formula,
                        family       = model_family,
                        data         = data,
                        prior        = prior,
                        iter         = iterations,
                        chains       = chains,
                        sample_prior = sample_prior,
                        cores        = cores,
                        control      = control,
                        file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_2_weak_prior, nsamples = 10) 

plot(fit_2_weak_prior, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

# Region of Practical Equivalence set to % of posterior standardized beta values within the range < .1 and > .1. That is, less than small effect size using Cohen's guidelines for R values. If > 95% of posterior is within this range, parameter can be said to be practically zero (i.e., evidence for null effect). Another option is to use Bayes Factors (below). ROPE on the posterior is less sensitive to the prior, but also usually requires greater N to estimate the parameter well enough to make such a conclusion.   
ROPE_data <- rope(fit_2_weak_prior, rope = c(-0.1, 0.1)) %>%  
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_2_weak_prior)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  dplyr::rename(`Std. Beta` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_2_weak_prior,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_2_weak_prior), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
H2_weak_sav_dic         <- fit_2_weak_prior %>% hypothesis(hypothesis = "influence_rate = 0", alpha = .05)  

# p_h2_weak <- plot(H2_weak_sav_dic, plot = FALSE, theme = theme_get())[[1]]  
# p_h2_weak + 
#   xlim(-3, 3) +
#   geom_vline(xintercept = H2_sav_dic$hypothesis$Estimate) +
#   theme_minimal()
plot(H2_weak_sav_dic)

# Posterior evidence ratio (Bayesian p value)
H2_weak_post_evid_ratio <- fit_2_weak_prior %>% hypothesis(hypothesis = "influence_rate > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/H2_weak_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(1/H2_weak_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.


## Informed prior

### Posterior of exp 1 as prior for exp 2

Parameterise the posterior distributions of the previous model (intercept, slope of influence rate, and its sigma) as normal distributions, use their M and SD as the prior for this model.

```{r}

fit_1_posterior <- as.data.frame(fit_1)

# plot posterior vs parameterisation of it.
## nb range may have to be manually adjusted for stat_function 

# b_Intercept
ggplot() +
  geom_density(data = fit_1_posterior, 
               aes(b_Intercept, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.5, 1.5)), 
                aes(x, color = "parameterised"),
                fun = dnorm,
                n = 101, 
                args = list(mean = mean(fit_1_posterior$b_Intercept), 
                            sd = sd(fit_1_posterior$b_Intercept)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_influenced
ggplot() +
  geom_density(data = fit_1_posterior, 
               aes(b_influencedyes, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.1, 0.6)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_1_posterior$b_influencedyes), 
                            sd = sd(fit_1_posterior$b_influencedyes)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_primetypeprimetype_B
ggplot() +
  geom_density(data = fit_1_posterior, 
               aes(b_prime_typeprime_type_B, color = "posterior")) +
  stat_function(data = data.frame(x = c(-0.6, -0.25)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_1_posterior$b_prime_typeprime_type_B), 
                            sd = sd(fit_1_posterior$b_prime_typeprime_type_B)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_influenced.prime_typeprime_type_B
ggplot() +
  geom_density(data = fit_1_posterior, 
               aes(b_influencedyes.prime_typeprime_type_B, color = "posterior")) +
  stat_function(data = data.frame(x = c(-3, -2)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_1_posterior$b_influencedyes.prime_typeprime_type_B), 
                            sd = sd(fit_1_posterior$b_influencedyes.prime_typeprime_type_B)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# sd_subject__Intercept
ggplot() +
  geom_density(data = fit_1_posterior, 
               aes(sd_subject__Intercept, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.75, 1.5)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_1_posterior$sd_subject__Intercept), 
                            sd = sd(fit_1_posterior$sd_subject__Intercept)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

```

```{r}

# an attempt to fit several different curves to the data and find the best one. needs work. 

# fitdistplus library might also be worth a look

# library(MASS)
# fit_1_parameterisation_normal  <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "normal")
# fit_1_parameterisation_t       <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "t")
# fit_1_parameterisation_weibull <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "weibull")
# fit_1_parameterisation_cauchy  <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "cauchy")
# fit_1_parameterisation_cauchy  <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "cauchy")
# fit_1_parameterisation_exponential    <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "exponential")
# fit_1_parameterisation_lognormal    <- fitdistr(fit_1_posterior$b_influence_rate, densfun = "lognormal")
# 
# 
# 
# fit_1_parameterisation_normal$loglik
# aic(fit_1_parameterisation_normal)
# 
# library(broom)
# rbind(glance(fit_1_parameterisation_normal), 
#       glance(fit_1_parameterisation_t), 
#       glance(fit_1_parameterisation_weibull),
#       glance(fit_1_parameterisation_cauchy),
#       glance(fit_1_parameterisation_exponential),
#       glance(fit_1_parameterisation_lognormal))
# 
# fit_1_parameterisation_exponential

```

### Fit model

```{r}

# check what parameteris require priors
get_prior(formula = model_formula,
          family  = model_family,
          data    = data)

# model specific setup
data          <- exp_2_ia_amp_trial_level_data

prior         <- c(prior(normal(0, 1)), # all parameters not covered by below, ie some associated with random effect for subject
                   prior(normal(0.978,  # mean(fit_1_posterior$b_Intercept)
                                0.101), # sd(fit_1_posterior$b_Intercept)
                         class = "Intercept"), 
                   
                   prior(normal(0.412,  # mean(fit_1_posterior$b_influencedyes)
                                0.069), # sd(fit_1_posterior$b_influencedyes)
                         class = "b", coef = "influencedyes"),
                   prior(normal(-0.414, # mean(fit_1_posterior$b_prime_typeprime_type_B)
                                0.042), # sd(fit_1_posterior$b_prime_typeprime_type_B)
                         class = "b", coef = "prime_typeprime_type_B"),
                   prior(normal(-2.558,  # mean(fit_1_posterior$b_influencedyes.prime_typeprime_type_B)
                                0.083), # sd(fit_1_posterior$b_influencedyes.prime_typeprime_type_B)
                         class = "b", coef = "influencedyes:prime_typeprime_type_B"),
                   
                   prior(normal(1.095,  # mean(fit_1_posterior$sd_subject__Intercept)
                                0.077), # sd(fit_1_posterior$sd_subject__Intercept)
                         class = "sd", coef = "Intercept", group = "subject"))

model_path    <- "models/fit_2_informed_prior_trial_level_data"

# fit model
fit_2 <- brm(formula      = model_formula,
             family       = model_family,
             data         = data,
             prior        = prior,
             iter         = iterations,
             chains       = chains,
             sample_prior = sample_prior,
             cores        = cores,
             control      = control,
             file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_2, nsamples = 10) 

plot(fit_2, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

ROPE_data <- rope(fit_2, rope = c(-0.1, 0.1)) %>%    # NEEDS MUCH THOUGHT, SEE OTHER SCRIPTS
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_2)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  mutate(Estimate = round(exp(Estimate), 2),
         SE = round(exp(SE), 2),
         Lower = round(exp(Lower), 2),
         Upper = round(exp(Upper), 2)) %>%
  dplyr::rename(`Odds Ratio` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_2,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_2), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
H2_sav_dic         <- fit_2 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B = 0", alpha = .05)  

# p_h2 <- plot(H2_sav_dic, plot = FALSE, theme = theme_get())[[1]]  
# p_h2 + 
#   xlim(-3, 3) +
#   geom_vline(xintercept = H2_sav_dic$hypothesis$Estimate) +
#   theme_minimal()
plot(H2_sav_dic)

# Posterior evidence ratio (Bayesian p value)
H2_post_evid_ratio <- fit_2 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/H2_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(H2_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.

# Experiment 3

*Needs work from here down*

## Weak, non-informative prior

### Fit model

```{r}

# model specific setup
data          <- exp_3_ia_amp_trial_level_data
prior         <- c(set_prior("normal(0, 1)"))  # weakly informative prior used on all parameters, see https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
model_path    <- "models/fit_3_weak_prior_trial_level_data"

# fit model
fit_3_weak_prior <- brm(formula      = model_formula,
                        family       = model_family,
                        data         = data,
                        prior        = prior,
                        iter         = iterations,
                        chains       = chains,
                        sample_prior = sample_prior,
                        cores        = cores,
                        control      = control,
                        file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_3_weak_prior, nsamples = 10) 

plot(fit_3_weak_prior, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

# Region of Practical Equivalence set to % of posterior standardized beta values within the range < .1 and > .1. That is, less than small effect size using Cohen's guidelines for R values. If > 95% of posterior is within this range, parameter can be said to be practically zero (i.e., evidence for null effect). Another option is to use Bayes Factors (below). ROPE on the posterior is less sensitive to the prior, but also usually requires greater N to estimate the parameter well enough to make such a conclusion.   
ROPE_data <- rope(fit_3_weak_prior, rope = c(-0.1, 0.1)) %>%  
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_3_weak_prior)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  dplyr::rename(`Std. Beta` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_3_weak_prior,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_3_weak_prior), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
H3_weak_sav_dic         <- fit_3_weak_prior %>% hypothesis(hypothesis = "influence_rate = 0", alpha = .05)  

# p_h3_weak <- plot(H3_weak_sav_dic, plot = FALSE, theme = theme_get())[[1]]  
# p_h3_weak + 
#   xlim(-3, 3) +
#   geom_vline(xintercept = H3_sav_dic$hypothesis$Estimate) +
#   theme_minimal()
plot(H3_weak_sav_dic)

# Posterior evidence ratio (Bayesian p value)
H3_weak_post_evid_ratio <- fit_3_weak_prior %>% hypothesis(hypothesis = "influence_rate > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/H3_weak_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(1/H3_weak_sav_dic$hypothesis$Evid.Ratio, 5)`.


## Informed prior

### Posterior of exp 2 as prior for exp 3.

Parameterise the posterior distributions of the previous model (intercept, slope of influence rate, and its sigma) as normal distributions, use their M and SD as the prior for this model.

```{r}

fit_2_posterior <- as.data.frame(fit_2)

# plot posterior vs parameterisation of it.
## nb range may have to be manually adjusted for stat_function 

# b_Intercept
ggplot() +
  geom_density(data = fit_2_posterior, 
               aes(b_Intercept, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.5, 1.5)), 
                aes(x, color = "parameterised"),
                fun = dnorm,
                n = 101, 
                args = list(mean = mean(fit_2_posterior$b_Intercept), 
                            sd = sd(fit_2_posterior$b_Intercept)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_influenced
ggplot() +
  geom_density(data = fit_2_posterior, 
               aes(b_influencedyes, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.1, 0.6)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_2_posterior$b_influencedyes), 
                            sd = sd(fit_2_posterior$b_influencedyes)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_primetypeprimetype_B
ggplot() +
  geom_density(data = fit_2_posterior, 
               aes(b_prime_typeprime_type_B, color = "posterior")) +
  stat_function(data = data.frame(x = c(-0.6, -0.25)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_2_posterior$b_prime_typeprime_type_B), 
                            sd = sd(fit_2_posterior$b_prime_typeprime_type_B)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# b_influenced.prime_typeprime_type_B
ggplot() +
  geom_density(data = fit_2_posterior, 
               aes(b_influencedyes.prime_typeprime_type_B, color = "posterior")) +
  stat_function(data = data.frame(x = c(-3, -2)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_2_posterior$b_influencedyes.prime_typeprime_type_B), 
                            sd = sd(fit_2_posterior$b_influencedyes.prime_typeprime_type_B)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

# sd_subject__Intercept
ggplot() +
  geom_density(data = fit_2_posterior, 
               aes(sd_subject__Intercept, color = "posterior")) +
  stat_function(data = data.frame(x = c(0.75, 1.5)), 
                aes(x, color = "parameterised"),
                fun = dnorm, 
                n = 101, 
                args = list(mean = mean(fit_2_posterior$sd_subject__Intercept), 
                            sd = sd(fit_2_posterior$sd_subject__Intercept)), 
                linetype = "dashed") +
  scale_colour_viridis_d(begin = 0.3, end = 0.8, direction = -1)

```

### Fit model

```{r}

# check what parameteris require priors
get_prior(formula = model_formula,
          family  = model_family,
          data    = data)

# model specific setup
data          <- exp_3_ia_amp_trial_level_data

prior         <- c(prior(normal(0, 1)),      # all parameters not covered by below, ie some associated with random effect for subject
                   prior(normal(1.094817,   # mean(fit_2_posterior$b_Intercept)
                                0.07614113), # sd(fit_2_posterior$b_Intercept)
                         class = "Intercept"), 
                   
                   prior(normal(0.6891437,   # mean(fit_2_posterior$b_influencedyes)
                                0.04979764), # sd(fit_2_posterior$b_influencedyes)
                         class = "b", coef = "influencedyes"),
                   prior(normal(-0.4835802,  # mean(fit_2_posterior$b_prime_typeprime_type_B)
                                0.03142999), # sd(fit_2_posterior$b_prime_typeprime_type_B)
                         class = "b", coef = "prime_typeprime_type_B"),
                   prior(normal(--2.647502,   # mean(fit_2_posterior$b_influencedyes.prime_typeprime_type_B)
                                0.05752647), # sd(fit_2_posterior$b_influencedyes.prime_typeprime_type_B)
                         class = "b", coef = "influencedyes:prime_typeprime_type_B"),
                   
                   prior(normal(1.088308,    # mean(fit_2_posterior$sd_subject__Intercept)
                                0.05470965), # sd(fit_2_posterior$sd_subject__Intercept)
                         class = "sd", coef = "Intercept", group = "subject"))

model_path    <- "models/fit_3_informed_prior_trial_level_data"

# fit model
fit_3 <- brm(formula      = model_formula,
             family       = model_family,
             data         = data,
             prior        = prior,
             iter         = iterations,
             chains       = chains,
             sample_prior = sample_prior,
             cores        = cores,
             control      = control,
             file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_3, nsamples = 10) 

plot(fit_3, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

ROPE_data <- rope(fit_3, rope = c(-0.1, 0.1)) %>%    # NEEDS MUCH THOUGHT, SEE OTHER SCRIPTS
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_3)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  mutate(Estimate = round(exp(Estimate), 2),
         SE = round(exp(SE), 2),
         Lower = round(exp(Lower), 2),
         Upper = round(exp(Upper), 2)) %>%
  dplyr::rename(`Odds Ratio` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_3,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_3), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
H3_sav_dic         <- fit_3 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B = 0", alpha = .05)

# p_h3 <- plot(H3_sav_dic, plot = FALSE, theme = theme_get())[[1]]  
# p_h3 + 
#   xlim(-3, 3) +
#   geom_vline(xintercept = H3_sav_dic$hypothesis$Estimate) +
#   theme_minimal()
plot(H3_sav_dic)

# Posterior evidence ratio (Bayesian p value)
H3_post_evid_ratio <- fit_3 %>% hypothesis(hypothesis = "influencedyes:prime_typeprime_type_B > 0", alpha = .05)

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/H3_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(H3_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.



# Combination analysis

Kruschke argued that if you are doing a series of studies you can update your prior in two ways. First, do a combination analysis with the original prior (e.g., to overwhelm that prior with increasingly more data). This may rase the question about how you enter experiment into the model (e.g., as a "random" effect or "fixed", to use the frequentist terms). Second, one can parameterize the posterior of experiment K and use this as the prior of experiment K+1. Above I have employed the second strategy. I employ the first strategy below for comparison.    

See http://doingbayesiandataanalysis.blogspot.com/2014/08/how-to-use-mcmc-posterior-as-prior-for.html

## Weak, non-informative prior

### Fit model

```{r}

# model specific setup
model_formula <- absolute_int_amp_effect ~ influence_rate + (1 | Experiment)
data          <- combined_data
prior         <- c(set_prior("normal(0, 1)"))  # weakly informative prior used on all parameters, see https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
model_path    <- "models/fit_combination_weak_prior_trial_level_data"

# fit model
fit_combination <- brm(formula      = model_formula,
                       family       = model_family,
                       data         = data,
                       prior        = prior,
                       iter         = iterations,
                       chains       = chains,
                       sample_prior = sample_prior,
                       cores        = cores,
                       control      = control,
                       file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_combination, nsamples = 10) 

plot(fit_combination, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

# Region of Practical Equivalence set to % of posterior standardized beta values within the range < .1 and > .1. That is, less than small effect size using Cohen's guidelines for R values. If > 95% of posterior is within this range, parameter can be said to be practically zero (i.e., evidence for null effect). Another option is to use Bayes Factors (below). ROPE on the posterior is less sensitive to the prior, but also usually requires greater N to estimate the parameter well enough to make such a conclusion.   
ROPE_data <- rope(fit_combination, rope = c(-0.1, 0.1)) %>%  
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_combination)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  dplyr::rename(`Std. Beta` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_combination,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_combination), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
Hcomb_sav_dic <- fit_combination %>% hypothesis(hypothesis = "influence_rate = 0", alpha = .05)  

plot(Hcomb_sav_dic)

# # zoom in on zero
# p_hcomb <- plot(Hcomb_sav_dic, plot = FALSE, theme = theme_get())[[1]]
# p_hcomb +
#   xlim(-0.5, 0.5) +
#   geom_vline(xintercept = Hcomb_sav_dic$hypothesis$Estimate) +
#   theme_minimal()

# Posterior evidence ratio (Bayesian p value)
Hcomb_post_evid_ratio <- fit_combination %>% hypothesis(hypothesis = "influence_rate > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/Hcomb_sav_dic$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(1/Hcomb_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.


## Very weak, non-informative prior

Just to see the influence of the prior.

### Fit model

```{r}

# model specific setup
data          <- combined_data
prior         <- c(set_prior("normal(0, 10)"))  # Very weakly informative prior used on all parameters, see https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations
model_path    <- "models/fit_combination_very_weak_prior_trial_level_data"

# fit model
fit_combination_2 <- brm(formula      = model_formula,
                         family       = model_family,
                         data         = data,
                         prior        = prior,
                         iter         = iterations,
                         chains       = chains,
                         sample_prior = sample_prior,
                         cores        = cores,
                         control      = control,
                         file         = model_path)

```

### Posterior checks

```{r}

# check the fit between the posterior distribution and the observed data
pp_check(fit_combination_2, nsamples = 10) 

plot(fit_combination_2, ask = FALSE)

```

### Results

NB Not a box plot: outer error bars are 95% HDI, inner error bars are 50% HDI. 

```{r}

# Region of Practical Equivalence set to % of posterior standardized beta values within the range < .1 and > .1. That is, less than small effect size using Cohen's guidelines for R values. If > 95% of posterior is within this range, parameter can be said to be practically zero (i.e., evidence for null effect). Another option is to use Bayes Factors (below). ROPE on the posterior is less sensitive to the prior, but also usually requires greater N to estimate the parameter well enough to make such a conclusion.   
ROPE_data <- rope(fit_combination_2, rope = c(-0.1, 0.1)) %>%  
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_combination_2)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

# table
results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, `% inside ROPE`, Eff.Sample, Rhat) %>%
  dplyr::rename(`Std. Beta` = Estimate) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
  add_header_above(c(" " = 3, "95% CI" = 2, " " = 3))

# plot 
plot_model(fit_combination_2,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot(marginal_effects(fit_combination_2), points = TRUE, ask = FALSE)

```

#### Bayes factors

```{r}

# Savage-Dickey Bayes Factor (BF10)
Hcomb_2_sav_dic <- fit_combination_2 %>% hypothesis(hypothesis = "influence_rate = 0", alpha = .05)  

plot(Hcomb_2_sav_dic)

# # zoom in on zero
# p_hcomb_2 <- plot(Hcomb_2_sav_dic, plot = FALSE, theme = theme_get())[[1]]
# p_hcomb_2 +
#   xlim(-0.5, 0.5) +
#   geom_vline(xintercept = Hcomb_2_sav_dic$hypothesis$Estimate) +
#   theme_minimal()

# Posterior evidence ratio (Bayesian p value)
Hcomb_2_post_evid_ratio <- fit_combination_2 %>% hypothesis(hypothesis = "influence_rate > 0", alpha = .05)  

```

Savage-Dickey Bayes Factor (BF10) = `r round(1/Hcomb_2_post_evid_ratio$hypothesis$Evid.Ratio, 3)`.

Posterior evidence ratio (Bayesian p value) = `r round(1/Hcomb_2_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.

# Frequentist combination analysis

For comparison

```{r}

# fit model
library(lme4)

fit_combination_freq <- lmer(formula      = model_formula,
                             data         = data)

summary(fit_combination_freq)

plot_model(fit_combination_freq, type = "est")

```