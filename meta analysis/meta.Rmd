---
title: "Meta analysis"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

Meta analyses of pos-neg IA AMP, which was present in all studies. Other AMPs/IA AMPs were presented in only only one study each so can't be meta analysed. Meta analyses of both the participant level AMP effects and the trial type level data are included. *This seems redundant. Choose one? The former is more familiar, the latter is better powered.*

Rather than reporting the results of the IA AMP's prime_type*influence_rate interaction effect in each study, we could simply present it in Exp 1, where it is central to results, and then refer readers to the meta analysis of this effect at the end. This would decrease redundancy in reporting.

- Think about problem of inversions?

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

```{r}

# dependencies
library(tidyverse)
library(timesavers)
library(lme4)
library(effects)
library(metafor)
#library(pROC)

# source for raincloud plots
source("../geom_flat_violin.R")

# get data and do exclusions
## participant level
exp_1 <- read.csv("../experiment 1/data/processed/processed_data.csv") %>%
  mutate(experiment = 1, 
         AMP_effect_positive_negative = NA,
         AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump_influenced = NA,
         IA_AMP_effect_obama_trump_not_influenced = NA,
         IA_AMP_effect_positive_negative_influenced = NA,
         IA_AMP_effect_positive_negative_not_influenced = NA,
         party = NA,
         politics = NA,
         demand = NA,
         demand_pn = NA,
         demand_to = NA,
         influence_general_pn = NA,
         influence_general_to = NA,
         intentionality_pn = NA,
         intentionality_to = NA,
         self_exclusion_1other = NA,
         unintentionality_pn = NA,
         unintentionality_to = NA,
         influence_rate_obama_trump = NA,
         influence_rate_positive_negative = NA)

exp_2 <- read.csv("../experiment 2/data/processed/processed_data.csv") %>%
  mutate(experiment = 2, 
         AMP_effect_positive_negative = NA,
         AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump_influenced = NA,
         IA_AMP_effect_obama_trump_not_influenced = NA,
         IA_AMP_effect_positive_negative_influenced = NA,
         IA_AMP_effect_positive_negative_not_influenced = NA,
         party = NA,
         politics = NA,
         demand = NA,
         demand_pn = NA,
         demand_to = NA,
         influence_general_pn = NA,
         influence_general_to = NA,
         intentionality_pn = NA,
         intentionality_to = NA,
         self_exclusion_1other = NA,
         unintentionality_pn = NA,
         unintentionality_to = NA,
         influence_rate_obama_trump = NA,
         influence_rate_positive_negative = NA)

exp_3 <- read.csv("../experiment 3/data/processed/processed_data.csv") %>%
  mutate(experiment = 3, 
         AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump = NA,
         IA_AMP_effect_obama_trump_influenced = NA,
         IA_AMP_effect_obama_trump_not_influenced = NA,
         IA_AMP_effect_positive_negative_influenced = NA,
         IA_AMP_effect_positive_negative_not_influenced = NA,
         demand_pn = NA,
         demand_to = NA,
         influence_general_pn = NA,
         influence_general_to = NA,
         intentionality_pn = NA,
         intentionality_to = NA,
         self_exclusion_1other = NA,
         unintentionality_pn = NA,
         unintentionality_to = NA,
         AMP_effect_positive_negative = NA,
         influence_rate_obama_trump = NA,
         influence_rate_positive_negative = NA)

exp_4 <- read.csv("../experiment 4 pilot/data/processed/processed_data.csv") %>%
  mutate(experiment = 4, 
         unintentionality = NA,
         intentionality = NA,
         demand = NA,
         influence_general = NA,
         influence_rate = NA,
         AMP_effect_obama_trump = NA,
         AMP_effect_positive_negative = NA)

combined_participant_level_data <- rbind(exp_1, exp_2, exp_3, exp_4) %>%
  select(sort(names(.))) %>%
  filter(complete_data == TRUE & self_exclusion_1 == "Yes, use my data") %>%
  mutate(influence_rate = ifelse(is.na(influence_rate), 
                                 influence_rate_positive_negative, influence_rate)) %>%
  mutate(unique_id = paste(experiment, subject, sep = "_")) %>%
  select(unique_id, IA_AMP_effect_positive_negative, influence_rate, experiment)


## trial level
exp_1_trial_level <- read.csv("../experiment 1/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(experiment = 1)

exp_2_trial_level <- read.csv("../experiment 2/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(experiment = 2)

exp_3_trial_level <- read.csv("../experiment 3/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(experiment = 3)

exp_4_trial_level <- read.csv("../experiment 4 pilot/data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
  mutate(experiment = 4)

combined_trial_level_data <- rbind(exp_1_trial_level, 
                                   exp_2_trial_level,
                                   exp_3_trial_level,
                                   exp_4_trial_level) %>%
  filter(complete_data == TRUE & self_exclusion_1 == "Yes, use my data") %>%
  mutate(unique_id = paste(experiment, subject, sep = "_"),
         prime_type = dplyr::recode(prime_type,
                                    "prime_type_A" = "Positive",
                                    "prime_type_B" = "Negative")) %>%
  select(-subject)

```

# Participant level analysis

## Meta analysis of the AMP effect

```{r}

# fit models
model_exp_1_part <- combined_participant_level_data %>%
  filter(experiment == 1) %>%
  lm(IA_AMP_effect_positive_negative ~ 1, 
     data = .)

model_exp_2_part <- combined_participant_level_data %>%
  filter(experiment == 2) %>%
  lm(IA_AMP_effect_positive_negative ~ 1, 
     data = .)

model_exp_3_part <- combined_participant_level_data %>%
  filter(experiment == 3) %>%
  lm(IA_AMP_effect_positive_negative ~ 1, 
     data = .)

model_exp_4_part <- combined_participant_level_data %>%
  filter(experiment == 4) %>%
  lm(IA_AMP_effect_positive_negative ~ 1, 
     data = .)

# extract coefficients
fixed_effects_exp_1_part <- summary(model_exp_1_part)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 1)

fixed_effects_exp_2_part <- summary(model_exp_2_part)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 2)

fixed_effects_exp_3_part <- summary(model_exp_3_part)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 3)

fixed_effects_exp_4_part <- summary(model_exp_4_part)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 4)

fixed_effects_part <- rbind(fixed_effects_exp_1_part, 
                            fixed_effects_exp_2_part,
                            fixed_effects_exp_3_part, 
                            fixed_effects_exp_4_part)

# reshape - requires models be bootstrapped prior to this
amp_participant_data_for_meta_analysis <- fixed_effects_part %>%
  mutate(
    # beta
    yi = Estimate,
    # SE
    sei = `Std. Error`,
    # convert SE to variance
    vi = sei^2
  ) %>%
  select(Experiment, yi, vi)

# fit Random Effects model 
meta_fit_amp_effect_participants <- 
  rma(yi, vi,
      data = amp_participant_data_for_meta_analysis,
      slab = paste(Experiment))

# make predictions converting to odds ratios
predictions_amp_part <-
  predict(meta_fit_amp_effect_participants, digits = 5) %>%
  as.data.frame() %>%
  gather() %>%
  round_df(2) %>%
  dplyr::rename(metric = key,
                estimate = value) %>%
  mutate(metric = dplyr::recode(metric,
                                "pred" = "Meta analysed OR",
                                "ci.lb" = "95% CI lower",
                                "ci.ub" = "95% CI upper",
                                "cr.lb" = "95% CR lower",
                                "cr.ub" = "95% CR upper"))

# plot
forest(meta_fit_amp_effect_participants,
       xlab = "Beta",
       addcred = TRUE)
# ## add column headings to the plot
# text(-6.3, 6.8, "Participant", pos = 4)
# text( 8.4, 6.8, "Odds Ratio [95% CI]", pos = 2)

# summarize results
meta_effect_amp_part <- 
  paste0("Meta analysis: k = ", meta_fit_amp_effect_participants$k, 
         ", Beta = ", predictions_amp_part$estimate[1],
         ", 95% CI [", predictions_amp_part$estimate[3], ", ", predictions_amp_part$estimate[4], "]",  # watch out for indexing - se returned for some analyses and not others
         ", 95% CR [", predictions_amp_part$estimate[5], ", ", predictions_amp_part$estimate[6], "]",
         ", p = ", signif(2*pnorm(-abs(meta_fit_amp_effect_participants$zval)), digits = 1))  # exact p value from z score

meta_heterogeneity_amp_part <- 
  paste0("Heterogeneity tests: Q(df = ", meta_fit_amp_effect_participants$k - 1, ") = ", 
         round(meta_fit_amp_effect_participants$QE, 2), 
         ", p = ", ifelse(meta_fit_amp_effect_participants$pval < 0.001, "< .001",
                          as.character(round(meta_fit_amp_effect_participants$pval, 3))),
         ", tau^2 = ", round(meta_fit_amp_effect_participants$tau2, 2), 
         ", I^2 = ",   round(meta_fit_amp_effect_participants$I2, 2),
         ", H^2 = ",   round(meta_fit_amp_effect_participants$H2, 2))

```

`r meta_effect_amp_part`

`r meta_heterogeneity_amp_part`

# Trial level analysis

## Meta analysis of the AMP effect

```{r}

# fit models
model_exp_1_amp <- combined_trial_level_data %>%
  filter(experiment == 1) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_2_amp <- combined_trial_level_data %>%
  filter(experiment == 2) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_3_amp <- combined_trial_level_data %>%
  filter(experiment == 3) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_4_amp <- combined_trial_level_data %>%
  filter(experiment == 4) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

# extract coefficients
fixed_effects_exp_1_amp <- summary(model_exp_1_amp)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 1)

fixed_effects_exp_2_amp <- summary(model_exp_2_amp)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 2)

fixed_effects_exp_3_amp <- summary(model_exp_3_amp)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 3)

fixed_effects_exp_4_amp <- summary(model_exp_4_amp)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 4)

amp_effects <- rbind(fixed_effects_exp_1_amp, 
                     fixed_effects_exp_2_amp, 
                     fixed_effects_exp_3_amp, 
                     fixed_effects_exp_4_amp) %>%
  filter(effect == "prime_typePositive")


# reshape - requires models be bootstrapped prior to this
amp_data_for_meta_analysis <- amp_effects %>%
  mutate(
    # log odds
    yi = Estimate,
    # SE
    sei = `Std. Error`,
    # convert SE to variance
    vi = sei^2
  ) %>%
  select(Experiment, yi, vi)

# fit Random Effects model 
meta_fit_amp_effect <- 
  rma(yi, vi,
      data = amp_data_for_meta_analysis,
      slab = paste(Experiment))

# make predictions converting to odds ratios
predictions_amp <-
  predict(meta_fit_amp_effect, transf = exp, digits = 5) %>%
  as.data.frame() %>%
  gather() %>%
  round_df(2) %>%
  dplyr::rename(metric = key,
                estimate = value) %>%
  mutate(metric = dplyr::recode(metric,
                                "pred" = "Meta analysed OR",
                                "ci.lb" = "95% CI lower",
                                "ci.ub" = "95% CI upper",
                                "cr.lb" = "95% CR lower",
                                "cr.ub" = "95% CR upper"))

# plot
forest(meta_fit_amp_effect,
       xlab = "Odds ratio",
       addcred = TRUE,  # credibility intervals
       atransf = exp)
# ## add column headings to the plot
# text(-6.3, 6.8, "Participant", pos = 4)
# text( 8.4, 6.8, "Odds Ratio [95% CI]", pos = 2)

# summarize results
meta_effect_amp <- 
  paste0("Meta analysis: k = ", meta_fit_amp_effect$k, 
         ", OR = ", predictions_amp$estimate[1],
         ", 95% CI [", predictions_amp$estimate[2], ", ", predictions_amp$estimate[3], "]",
         ", 95% CR [", predictions_amp$estimate[4], ", ", predictions_amp$estimate[5], "]",
         ", p = ", signif(2*pnorm(-abs(meta_fit_amp_effect$zval)), digits = 1))  # exact p value from z score

meta_heterogeneity_amp <- 
  paste0("Heterogeneity tests: Q(df = ", meta_fit_amp_effect$k - 1, ") = ", round(meta_fit_amp_effect$QE, 2), 
         ", p = ", ifelse(meta_fit_amp_effect$pval < 0.001, "< .001", as.character(round(meta_fit_amp_effect$pval, 3))),
         ", tau^2 = ", round(meta_fit_amp_effect$tau2, 2), 
         ", I^2 = ",   round(meta_fit_amp_effect$I2, 2),
         ", H^2 = ",   round(meta_fit_amp_effect$H2, 2))

```

`r meta_effect_amp`

`r meta_heterogeneity_amp`

## Meta analysis of the AMP effect*influence interaction

```{r}

# fit models
model_exp_1 <- combined_trial_level_data %>%
  filter(experiment == 1) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type * influenced + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_2 <- combined_trial_level_data %>%
  filter(experiment == 2) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type * influenced + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_3 <- combined_trial_level_data %>%
  filter(experiment == 3) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type * influenced + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

model_exp_4 <- combined_trial_level_data %>%
  filter(experiment == 4) %>%
  mutate(prime_type = fct_relevel(prime_type,
                                  "Negative",
                                  "Positive")) %>%
  glmer(rating ~ prime_type * influenced + (1 | unique_id), 
        family = binomial(link = "logit"),
        data = .)

# extract coefficients
fixed_effects_exp_1 <- summary(model_exp_1)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 1)

fixed_effects_exp_2 <- summary(model_exp_2)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 2)

fixed_effects_exp_3 <- summary(model_exp_3)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 3)

fixed_effects_exp_4 <- summary(model_exp_4)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "effect") %>%
  mutate(Experiment = 4)

interaction_effects <- rbind(fixed_effects_exp_1, 
                             fixed_effects_exp_2, 
                             fixed_effects_exp_3, 
                             fixed_effects_exp_4) %>%
  filter(effect == "prime_typePositive:influenced")


# reshape - requires models be bootstrapped prior to this
data_for_meta_analysis <- interaction_effects %>%
  mutate(
    # log odds
    yi = Estimate,
    # SE
    sei = `Std. Error`,
    # convert SE to variance
    vi = sei^2
  ) %>%
  select(Experiment, yi, vi)

# fit Random Effects model 
meta_fit <- rma(yi, vi,
                data = data_for_meta_analysis,
                slab = paste(Experiment))

# make predictions converting to odds ratios
predictions <-
  predict(meta_fit, transf = exp, digits = 5) %>%
  as.data.frame() %>%
  gather() %>%
  round_df(2) %>%
  dplyr::rename(metric = key,
                estimate = value) %>%
  mutate(metric = dplyr::recode(metric,
                                "pred" = "Meta analysed OR",
                                "ci.lb" = "95% CI lower",
                                "ci.ub" = "95% CI upper",
                                "cr.lb" = "95% CR lower",
                                "cr.ub" = "95% CR upper"))

# plot
forest(meta_fit,
       xlab = "Odds ratio",
       addcred = TRUE,  # credibility intervals
       atransf = exp)
# ## add column headings to the plot
# text(-6.3, 6.8, "Experiment", pos = 4)
# text( 8.4, 6.8, "Odds Ratio [95% CI]", pos = 2)

# summarize results
meta_effect_interaction <- 
  paste0("Meta analysis: k = ", meta_fit$k, 
         ", OR = ", predictions$estimate[1],
         ", 95% CI [", predictions$estimate[2], ", ", predictions$estimate[3], "]",
         ", 95% CR [", predictions$estimate[4], ", ", predictions$estimate[5], "]",
         ", p = ", signif(2*pnorm(-abs(meta_fit$zval)), digits = 1))  # exact p value from z score

meta_heterogeneity_interaction <- 
  paste0("Heterogeneity tests: Q(df = ", meta_fit$k - 1, ") = ", round(meta_fit$QE, 2), 
         ", p = ", ifelse(meta_fit$pval < 0.001, "< .001", as.character(round(meta_fit$pval, 3))),
         ", tau^2 = ", round(meta_fit$tau2, 2), 
         ", I^2 = ",   round(meta_fit$I2, 2),
         ", H^2 = ",   round(meta_fit$H2, 2))

```

`r meta_effect_interaction`

`r meta_heterogeneity_interaction`

### Plot meta analysed interaction

```{r fig.height=8, fig.width=6.5}

# plot 1 - quintiles of interaction effect 

# model
model_h2 <- glmer(rating ~ prime_type * influenced + (1 | unique_id) + (1 | experiment), 
                  family = binomial(link = "logit"),
                  data = combined_trial_level_data)

# predictions
model_h2_predicted_effects <- 
  as.data.frame(effect("prime_type:influenced", model_h2, xlevels = 10)) %>%
  round_df(2) %>%
  mutate(prime_type = fct_relevel(prime_type, "Positive", "Negative"))

# plot
p1 <- 
  ggplot(data = model_h2_predicted_effects,
         aes(x = prime_type, y = fit, colour = influenced, group = influenced)) +
  geom_line() +
  ylab("Mean evaluation on IA AMP") +
  xlab("Prime type") +
  #scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_colour_viridis_c(direction = -1) +
  theme_classic() + 
  labs(colour = "Proportion of\ninfluenced trials") +
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1.00), 
                     labels = c("(Negative) 0.00", "0.25", "0.50", "0.75", "(Positive) 1.00"), 
                     limits = c(0, 1))


# Plot 2 - differences between influenced and non influenced trials

## add these probabilities back to the original data frame (omitting missing values) 
predictions <- combined_trial_level_data %>%
  select(prime_type, influenced, unique_id,  experiment) %>%
  na.omit %>%
  mutate(prob = predict(model_h2, type = c("response")),
         `Influence of prime\non evaluation of target` = dplyr::recode(influenced, 
                                                                       "0" = "Uninfluenced trials",
                                                                       "1" = "Influenced trials"),
         prime_type = fct_relevel(prime_type, "Negative", "Positive"))

# plot
p2 <- 
  ggplot(data = predictions, 
         aes(x = as.factor(prime_type), 
             y = prob,
             fill = `Influence of prime\non evaluation of target`,
             color = `Influence of prime\non evaluation of target`)) +
  geom_flat_violin(position = position_nudge(x = .2, y = 0),
                   adjust = 1.5,
                   alpha = .5) +
  geom_point(position = position_jitter(width = .15), 
             size = 0.25, 
             alpha = 0.1) +
  scale_colour_viridis_d(begin = 0.3, end = 0.7) +
  scale_fill_viridis_d(begin = 0.3, end = 0.7) +
  coord_flip() +
  theme_classic() +
  xlab("Prime type") +
  ylab("Evaluation on IA AMP") +
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1.00), 
                     labels = c("0.00\n(Negative)", "0.25", "0.50", "0.75", "1.00\n(Positive)"), 
                     limits = c(0, 1))

# plot
library(patchwork)
p1 + p2 + plot_layout(ncol = 1)


```

