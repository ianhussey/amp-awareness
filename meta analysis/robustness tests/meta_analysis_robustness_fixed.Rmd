---
title: "Meta analyses robustness tests"
subtitle: "Comparing metric vs ordinal fixed effects models"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

Given that residuals from the metric models employed in the main analyses appear to demonstrate some deviation from normality, we therefore conducted robustness tests on the meta analyses. Models for each experiment were refitted using both rank model and standardized metric models (for both IV and DV). This allowed us to directly compare both the conclusions (congruence in significance decisions) and estimation (overlap of the CIs between the two approaches). If all parametric assumptions were met, estimates across these two types of models should converge. 

Code/analyses are adapted from the meta analyses. Meta analyses of the key hypothesis tests are refitted, i.e., influence rates predicting (IA-)AMP effects.

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```

```{r}

# dependencies
library(tidyverse)
library(timesavers)
library(lme4)
library(effects)
library(metafor)
library(patchwork)
library(ggExtra)
library(sjPlot)
library(kableExtra)
library(knitr)

# disable scientific notation
options(scipen = 999) 

# knitr output for html
options(knitr.table.format = "html")


# custom functions --------------------

zscore_to_p <- function(z){
  2*pnorm(-abs(z))
}

# fit models to individual experiments and extract an effect of interest
fit_lm_model_and_extract_effect <- function(data, experiment_n, formula, effect, 
                                            IA_AMP_domain_name = NULL,
                                            AMP_domain_name = NULL) {
  require(tidyverse)
  
  if (!is.null(IA_AMP_domain_name)) {
    
    fit <- data %>%
      dplyr::filter(experiment == experiment_n & 
                      IA_AMP_domain == IA_AMP_domain_name) %>%
      lm(formula = formula, 
         data = .)
    
    results <- 
      summary(fit)$coefficients %>%
      as.data.frame() %>%
      rownames_to_column(var = "Effect") %>%
      dplyr::filter(Effect == effect) %>%
      mutate(Experiment = experiment_n,
             IA_AMP_domain = IA_AMP_domain_name,
             yi = Estimate,       # effect size
             vi = `Std. Error`^2) # convert SE to variance
    
  } else if (!is.null(AMP_domain_name)) {
    
    fit <- data %>%
      dplyr::filter(experiment == experiment_n & 
                      AMP_domain == AMP_domain_name) %>%
      lm(formula = formula, 
         data = .)
    
    results <- 
      summary(fit)$coefficients %>%
      as.data.frame() %>%
      rownames_to_column(var = "Effect") %>%
      dplyr::filter(Effect == effect) %>%
      mutate(Experiment = experiment_n,
             AMP_domain = AMP_domain_name,
             yi = Estimate,       # effect size
             vi = `Std. Error`^2) # convert SE to variance
    
  }
  
  return(results)
}

# get data
combined_participant_level_data <- read.csv("../data/combined_participant_level_data.csv") 

```

# Are robustness tests needed? 

The main analyses observe bimodality in influence rates. While linear (metric) regression models assume normality of residuals rather than normality of the IVs themselves, this nonetheless raised the question of whether residuals were indeed normally distributed. 

In order to assess whether robustness tests were indeed useful or necessary, we inspected the residuals from a randomly fixed-effects model: Experiment 2's H1b (participant level) for normality using QQ plots.

## Metric model

As used in the analyses and meta analyses.

```{r fig.height=6, fig.width=6}

# get data 
task_level_data <- read.csv("../../experiment 2/data/processed/processed_data.csv")

# exclusions
task_level_data_exclusions <- task_level_data %>%
  filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)



# model
fit_gauss <- lm(AMP_effect_positive_negative ~ influence_rate, 
                data = task_level_data_exclusions)

# tab_model(fit_gauss, 
#           ci.hyphen = ", ", 
#           show.est = FALSE,
#           show.std = TRUE,
#           emph.p = FALSE, 
#           digits.p = 6)

fit_gauss_stdres = rstandard(fit_gauss)
qqnorm(fit_gauss_stdres, 
       ylab = "Standardized Residuals", 
       xlab = "Normal Scores") 
qqline(fit_gauss_stdres)

```

- Some evidence of non normality in the residuals. 

## Rank model 

IVs and DV all ranked

```{r fig.height=6, fig.width=6}

# model
fit_ord <- 
  task_level_data_exclusions %>%
  mutate(rank_AMP_effect_positive_negative = rank(AMP_effect_positive_negative),
         rank_influence_rate = rank(influence_rate)) %>%
  lm(rank_AMP_effect_positive_negative ~ rank_influence_rate, 
     data = .)

# tab_model(fit_ord, 
#           ci.hyphen = ", ", 
#           show.est = FALSE,
#           show.std = TRUE,
#           emph.p = FALSE, 
#           digits.p = 6)

fit_ord_stdres = rstandard(fit_ord)
qqnorm(fit_ord_stdres, 
       ylab = "Standardized Residuals", 
       xlab = "Normal Scores") 
qqline(fit_ord_stdres)

```

- Residuals are more normally distributed.

# Does influence rate predict the magnitude of (IA)AMP effects?

## IA-AMP

### Participant level

#### Main effect

##### Standardized metric models

scale(IA-AMP effect) ~ scale(IA-AMP influence rate) 

Absolute IA-AMP effects.

```{r}

formula <- as.formula("as.numeric(scale(abs(IA_AMP_effect))) ~ as.numeric(scale(influence_rate))")
effect  <- "as.numeric(scale(influence_rate))"

# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_1 <- rbind(
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 1, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 2, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 3, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 4, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 4, 
                                  IA_AMP_domain_name = "Politics",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 5, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect)
)

```

```{r}

# reshape data
data_temp <- results_for_meta_analysis_1 %>%
  dplyr::rename(V = vi)

# fit
fit <- rma.mv(yi     = yi,
              V      = V,
              random = ~ 1 | Experiment/IA_AMP_domain,
              data   = data_temp,
              slab   = paste(Experiment, IA_AMP_domain))

# plot
forest(fit,
       xlab = "Standardized Beta",
       addcred = TRUE,
       refline = 0)

# convert to OR, show CR
predict(fit) %>%
  as.data.frame() %>%
  round_df(2) %>%
  mutate(p = zscore_to_p(fit$zval))

```

##### Rank models

rank(IA-AMP effect) ~ rank(IA-AMP influence rate) 

Absolute IA-AMP effects.

```{r}

formula <- as.formula("rank(abs(IA_AMP_effect)) ~ rank(influence_rate)")
effect  <- "rank(influence_rate)"

# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_1 <- rbind(
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 1, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 2, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 3, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 4, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 4, 
                                  IA_AMP_domain_name = "Politics",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 5, 
                                  IA_AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect)
)

```

```{r}

# reshape data
data_temp <- results_for_meta_analysis_1 %>%
  dplyr::rename(V = vi)

# fit
fit <- rma.mv(yi     = yi,
              V      = V,
              random = ~ 1 | Experiment/IA_AMP_domain,
              data   = data_temp,
              slab   = paste(Experiment, IA_AMP_domain))

# plot
forest(fit,
       xlab = "Rank Beta",
       addcred = TRUE,
       refline = 0)

# convert to OR, show CR
predict(fit) %>%
  as.data.frame() %>%
  round_df(2) %>%
  mutate(p = zscore_to_p(fit$zval))

```

## AMP effect ~ IA-AMP influence rate

### Participant level 

#### Main effect

##### Standardized metric models

scale(AMP effect) ~ scale(IA-AMP influence rate)

Absolute AMP effects.

```{r}

formula <- as.formula("as.numeric(scale(abs(AMP_effect))) ~ as.numeric(scale(influence_rate))")
effect  <- "as.numeric(scale(influence_rate))"

# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_3 <- rbind(
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 2, 
                                  AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 3, 
                                  AMP_domain_name = "Politics",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 5, 
                                  AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect)
) 

```

```{r}

# reshape data
data_temp <- results_for_meta_analysis_3 %>%
  dplyr::rename(V = vi)

# fit
fit <- rma.mv(yi     = yi,
              V      = V,
              random = ~ 1 | Experiment/AMP_domain,
              data   = data_temp,
              slab   = paste(Experiment, AMP_domain))

# plot
forest(fit,
       xlab = "Standardized Beta",
       addcred = TRUE,
       refline = 0)

# convert to OR, show CR
predict(fit) %>%
  as.data.frame() %>%
  round_df(2) %>%
  mutate(p = zscore_to_p(fit$zval))

```

##### Rank models

rank(AMP effect) ~ rank(IA-AMP influence rate)

Absolute AMP effects.

```{r}

formula <- as.formula("rank(abs(AMP_effect)) ~ rank(influence_rate)")
effect  <- "rank(influence_rate)"

# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_3 <- rbind(
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 2, 
                                  AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 3, 
                                  AMP_domain_name = "Politics",
                                  formula = formula, 
                                  effect = effect),
  fit_lm_model_and_extract_effect(data = combined_participant_level_data, 
                                  experiment_n = 5, 
                                  AMP_domain_name = "Generic valence",
                                  formula = formula, 
                                  effect = effect)
) 

```

```{r}

# reshape data
data_temp <- results_for_meta_analysis_3 %>%
  dplyr::rename(V = vi)

# fit
fit <- rma.mv(yi     = yi,
              V      = V,
              random = ~ 1 | Experiment/AMP_domain,
              data   = data_temp,
              slab   = paste(Experiment, AMP_domain))

# plot
forest(fit,
       xlab = "Rank Beta",
       addcred = TRUE,
       refline = 0)

# convert to OR, show CR
predict(fit) %>%
  as.data.frame() %>%
  round_df(2) %>%
  mutate(p = zscore_to_p(fit$zval))

```

