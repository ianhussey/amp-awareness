dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = plotrix::std.error(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
ggplot() +
stat_density_ridges(data = data_plotting,
aes(x = IA_AMP_effect,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
geom = "density_ridges_gradient",
bandwidth = 0.35,
jittered_points = TRUE,
scale = 0.95,
rel_min_height = 0.05,
point_shape = "|",
point_size = 3,
size = 0.25,
position = position_points_jitter(height = 0, width = 0, yoffset = -0.05)) +
geom_errorbarh(data = data_summary_plotting,
aes(xmin = IA_AMP_effect_mean - IA_AMP_effect_se*1.96,
xmax = IA_AMP_effect_mean + IA_AMP_effect_se*1.96,
y = influence,
color = as.factor(party)),
height = 0.1,
position = position_nudge(y = -0.16, x = 0)) +
geom_point(data = data_summary_plotting,
aes(x = IA_AMP_effect_mean,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
position = position_nudge(y = -0.16, x = 0)) +
scale_colour_viridis_d(begin = 0.3, end = 0.7, alpha = 1) +
scale_fill_viridis_d(begin = 0.3, end = 0.7, alpha = 0.5) +
theme_classic() +
scale_x_continuous(breaks = c(-1.0, -0.5, 0.0, 0.5, 1.0),
labels = c("-1.0\n(Obama-bad/Trump-good)", "-0.5", "0.0", "0.5", "1.0\n(Obama-good/Trump-bad)")) +
ylab("Influence-awareness") +
xlab("Evaluation on IA-AMP") +
labs(color = "Political party") +
labs(name = "Political party") +
labs(fill = "Political party")
data_summary_plotting <- data_plotting %>%
group_by(party, influence) %>%
dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = plotrix::std.dev(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
data_summary_plotting <- data_plotting %>%
group_by(party, influence) %>%
dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = plotrix::std.deviation(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
data_summary_plotting <- data_plotting %>%
group_by(party, influence) %>%
dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = plotrix::sd(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
data_summary_plotting <- data_plotting %>%
group_by(party, influence) %>%
dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = sd(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
ggplot() +
stat_density_ridges(data = data_plotting,
aes(x = IA_AMP_effect,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
geom = "density_ridges_gradient",
bandwidth = 0.35,
jittered_points = TRUE,
scale = 0.95,
rel_min_height = 0.05,
point_shape = "|",
point_size = 3,
size = 0.25,
position = position_points_jitter(height = 0, width = 0, yoffset = -0.05)) +
geom_errorbarh(data = data_summary_plotting,
aes(xmin = IA_AMP_effect_mean - IA_AMP_effect_se*1.96,
xmax = IA_AMP_effect_mean + IA_AMP_effect_se*1.96,
y = influence,
color = as.factor(party)),
height = 0.1,
position = position_nudge(y = -0.16, x = 0)) +
geom_point(data = data_summary_plotting,
aes(x = IA_AMP_effect_mean,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
position = position_nudge(y = -0.16, x = 0)) +
scale_colour_viridis_d(begin = 0.3, end = 0.7, alpha = 1) +
scale_fill_viridis_d(begin = 0.3, end = 0.7, alpha = 0.5) +
theme_classic() +
scale_x_continuous(breaks = c(-1.0, -0.5, 0.0, 0.5, 1.0),
labels = c("-1.0\n(Obama-bad/Trump-good)", "-0.5", "0.0", "0.5", "1.0\n(Obama-good/Trump-bad)")) +
ylab("Influence-awareness") +
xlab("Evaluation on IA-AMP") +
labs(color = "Political party") +
labs(name = "Political party") +
labs(fill = "Political party")
data_summary_plotting <- data_plotting %>%
group_by(party, influence) %>%
dplyr::summarize(IA_AMP_effect_mean = mean(IA_AMP_effect, na.rm = TRUE),
IA_AMP_effect_se = plotrix::std.error(IA_AMP_effect, na.rm = TRUE)) %>%
ungroup()
ggplot() +
stat_density_ridges(data = data_plotting,
aes(x = IA_AMP_effect,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
geom = "density_ridges_gradient",
bandwidth = 0.35,
jittered_points = TRUE,
scale = 0.95,
rel_min_height = 0.05,
point_shape = "|",
point_size = 3,
size = 0.25,
position = position_points_jitter(height = 0, width = 0, yoffset = -0.05)) +
geom_errorbarh(data = data_summary_plotting,
aes(xmin = IA_AMP_effect_mean - IA_AMP_effect_se*1.96,
xmax = IA_AMP_effect_mean + IA_AMP_effect_se*1.96,
y = influence,
color = as.factor(party)),
height = 0.1,
position = position_nudge(y = -0.16, x = 0)) +
geom_point(data = data_summary_plotting,
aes(x = IA_AMP_effect_mean,
y = influence,
fill = as.factor(party),
color = as.factor(party)),
position = position_nudge(y = -0.16, x = 0)) +
scale_colour_viridis_d(begin = 0.3, end = 0.7, alpha = 1) +
scale_fill_viridis_d(begin = 0.3, end = 0.7, alpha = 0.5) +
theme_classic() +
scale_x_continuous(breaks = c(-1.0, -0.5, 0.0, 0.5, 1.0),
labels = c("-1.0\n(Obama-bad/Trump-good)", "-0.5", "0.0", "0.5", "1.0\n(Obama-good/Trump-bad)")) +
ylab("Influence-awareness") +
xlab("Evaluation on IA-AMP") +
labs(color = "Political party") +
labs(name = "Political party") +
labs(fill = "Political party")
install.packages("Partiallyoverlapping")
install.packages("BayesFactor")
# dependencies
library(tidyverse)
library(lme4)
library(sjPlot)
library(effects)
library(DescTools)
library(Rmisc)
library(effsize)
library(psych)
library(broom)
library(kableExtra)
# devtools::install_github("ianhussey/timesavers")
library(timesavers)  # for round_df()
library(plotrix)
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_amp_data <- read.csv("../data/processed/trial_level_amp_positive_negative_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = as.numeric(influenced))
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_amp_data_exclusions <- trial_level_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# full model
full_model <- BayesFactor::lmBF(AMP_effect_positive_negative ~ influence_rate + experiment + influence_rate:experiment, data = combined_exps_2_and_5)
# bring in exp 2 data
exp_2_df <- read_csv("../../experiment 2/data/processed/processed_data.csv") %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE) %>%
dplyr::mutate(experiment = "exp_2") %>%
select(subject, AMP_effect_positive_negative, influence_rate, experiment)
# mutate eperiment column for exp 5 data
exp_5_df <- task_level_data_exclusions %>%
dplyr::mutate(experiment = "exp_5") %>%
select(subject, AMP_effect_positive_negative, influence_rate, experiment)
# model
fit_comparison <- lm(AMP_effect_positive_negative ~ influence_rate * experiment,
data = combined_exps_2_and_5)
# create new df combining experiment 2 and 5 data
combined_exps_2_and_5 <- bind_rows(exp_2_df, exp_5_df)
# model
fit_comparison <- lm(AMP_effect_positive_negative ~ influence_rate * experiment,
data = combined_exps_2_and_5)
# plot
plot_model(fit_comparison, type = "int")
# full model
full_model <- BayesFactor::lmBF(AMP_effect_positive_negative ~ influence_rate + experiment + influence_rate:experiment, data = combined_exps_2_and_5)
# model minus interaction
no_interaction_model <- BayesFactor::lmBF(AMP_effect_positive_negative ~ influence_rate + experiment, data = combined_exps_2_and_5)
# BF10
full_model / no_interaction_model
# Age mean and SD
task_level_data_exclusions %>%
filter(!(is.na(age))) %>%
mutate(age = as.numeric(as.character(age))) %>%
dplyr::summarise("age (mean)" = mean(age),
"age (standard deviation)" = sd(age)) %>%
round_df(2)
install.packages("ggExtra")
install.packages("patchwork")
devtools::install_github("thomasp85/patchwork")
## add these probabilities back to the original data frame (omitting missing values)
predictions <- combined_trial_level_data %>%
dplyr::select(prime_type, influenced, unique_id,  experiment) %>%
na.omit %>%
mutate(prob = predict(model_2, type = c("response")),
`Influence of prime\non evaluation of target` = dplyr::recode(influenced,
"0" = "Uninfluenced trials",
"1" = "Influenced trials"),
prime_type = fct_relevel(prime_type, "Negative", "Positive"))
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# dependencies
library(tidyverse)
library(timesavers)
library(lme4)
library(effects)
library(metafor)
library(patchwork)
library(ggExtra)
library(sjPlot)
library(kableExtra)
library(knitr)
# source for raincloud plots
source("geom_flat_violin.R")
# disable scientific notation
options(scipen = 999)
# knitr output for html
options(knitr.table.format = "html")
# custom functions --------------------
zscore_to_p <- function(z){
2*pnorm(-abs(z))
}
# fit models to individual experiments and extract an effect of interest
fit_lm_model_and_extract_effect <- function(data, experiment_n, formula, effect,
IA_AMP_domain_name = NULL,
AMP_domain_name = NULL) {
require(tidyverse)
if (!is.null(IA_AMP_domain_name)) {
fit <- data %>%
dplyr::filter(experiment == experiment_n &
IA_AMP_domain == IA_AMP_domain_name) %>%
lm(formula = formula,
data = .)
results <-
summary(fit)$coefficients %>%
as.data.frame() %>%
rownames_to_column(var = "Effect") %>%
dplyr::filter(Effect == effect) %>%
mutate(Experiment = experiment_n,
IA_AMP_domain = IA_AMP_domain_name,
yi = Estimate,       # effect size
vi = `Std. Error`^2) # convert SE to variance
} else if (!is.null(AMP_domain_name)) {
fit <- data %>%
dplyr::filter(experiment == experiment_n &
AMP_domain == AMP_domain_name) %>%
lm(formula = formula,
data = .)
results <-
summary(fit)$coefficients %>%
as.data.frame() %>%
rownames_to_column(var = "Effect") %>%
dplyr::filter(Effect == effect) %>%
mutate(Experiment = experiment_n,
AMP_domain = AMP_domain_name,
yi = Estimate,       # effect size
vi = `Std. Error`^2) # convert SE to variance
}
return(results)
}
# fit models to individual experiments and extract an effect of interest
fit_glmer_model_and_extract_effect <- function(data, experiment_n, formula, effect, domain_name = NULL) {
require(tidyverse)
if (!is.null(domain_name)) {
fit <- data %>%
dplyr::filter(experiment == experiment_n &
domain == domain_name) %>%
glmer(formula = formula,
family = binomial(link = "logit"),
data = .)
results <-
summary(fit)$coefficients %>%
as.data.frame() %>%
rownames_to_column(var = "Effect") %>%
dplyr::filter(Effect == effect) %>%
mutate(Experiment = experiment_n,
domain = domain_name,
yi = Estimate,       # effect size
vi = `Std. Error`^2) # convert SE to variance
} else {
fit <- data %>%
dplyr::filter(experiment == experiment_n) %>%
glmer(formula = formula,
family = binomial(link = "logit"),
data = .)
results <-
summary(fit)$coefficients %>%
as.data.frame() %>%
rownames_to_column(var = "Effect") %>%
dplyr::filter(Effect == effect) %>%
mutate(Experiment = experiment_n,
yi = Estimate,       # effect size
vi = `Std. Error`^2) # convert SE to variance
}
return(results)
}
# get data
combined_participant_level_data <- read.csv("data/combined_participant_level_data.csv")
combined_trial_level_data       <- read.csv("data/combined_trial_level_data.csv")
formula <- as.formula("abs(IA_AMP_effect) ~ influence_rate")
effect  <- "influence_rate"
# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_1 <- rbind(
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 1,
IA_AMP_domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 2,
IA_AMP_domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 3,
IA_AMP_domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 4,
IA_AMP_domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 4,
IA_AMP_domain_name = "Politics",
formula = formula,
effect = effect),
fit_lm_model_and_extract_effect(data = combined_participant_level_data,
experiment_n = 5,
IA_AMP_domain_name = "Generic valence",
formula = formula,
effect = effect)
)
# reshape data
data_temp <- results_for_meta_analysis_1 %>%
dplyr::rename(V = vi)
# fit
fit <- rma.mv(yi     = yi,
V      = V,
random = ~ 1 | Experiment/IA_AMP_domain,
data   = data_temp,
slab   = paste(Experiment, IA_AMP_domain))
# plot
forest(fit,
xlab = "Beta",
addcred = TRUE,
refline = 0)
# convert to OR, show CR
predict(fit) %>%
as.data.frame() %>%
round_df(2) %>%
mutate(p = zscore_to_p(fit$zval))
temp_data <- combined_participant_level_data %>%
select(experiment, IA_AMP_domain, IA_AMP_effect, influence_rate)
ggplot(temp_data,
aes(influence_rate, IA_AMP_effect, color = IA_AMP_domain)) +
geom_smooth(method = "lm") +
scale_color_viridis_d(end = 0.7, begin = 0.3) +
theme_classic() +
xlab("IA-AMP influence-awareness rate") +
ylab("Absolute magnitude of IA-AMP effect") +
labs(color = "Domain") +
labs(name = "Domain") +
labs(fill = "Domain") +
theme(legend.position = c(0.3, .8))
formula <- as.formula("rating ~ prime_type * influenced + (1 | unique_id)")
effect  <- "prime_typePositive:influenced"
# apply models to individual experiments, extract results for key effect
results_for_meta_analysis_2 <- rbind(
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 1,
domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 2,
domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 3,
domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 4,
domain_name = "Generic valence",
formula = formula,
effect = effect),
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 4,
domain_name = "Politics",
formula = formula,
effect = effect),
fit_glmer_model_and_extract_effect(data = combined_trial_level_data,
experiment_n = 5,
domain_name = "Generic valence",
formula = formula,
effect = effect)
)
# reshape data
data_temp <- results_for_meta_analysis_2 %>%
dplyr::rename(V = vi)
# fit
fit <- rma.mv(yi     = yi,
V      = V,
random = ~ 1 | Experiment/domain,
data   = data_temp,
slab   = paste(Experiment, domain))
# plot
forest(fit,
xlab = "Odds Ratio",
addcred = TRUE,
refline = 1,
atransf = exp)
# convert to OR, show CR
OR <- predict(fit) %>%
as.data.frame() %>%
exp() %>%
select(-se) %>%
round_df(2)
## print as odds ratios
OR %>%
mutate(p = zscore_to_p(fit$zval))
OR_to_d(OR) %>%
round_df(2)
# # fit combined model
# model_2 <- glmer(rating ~ prime_type * influenced + (1 | experiment/unique_id) + (1 | domain),
#                  family = binomial(link = "logit"),
#                  data = combined_trial_level_data)
#
# save(model_2, file = "model_2.Rdata")
load("model_2.RData")
# predictions
model_2_predicted_effects <-
as.data.frame(effect("prime_type:influenced", model_2, xlevels = 50)) %>%
round_df(2) %>%
mutate(prime_type = fct_relevel(prime_type, "Negative", "Positive"))
# Plot 1 -  quantiles (10ths) of interaction effect
ggplot(data = model_2_predicted_effects,
aes(x = prime_type, y = fit, colour = influenced, group = influenced)) +
geom_line() +
ylab("Mean evaluation on IA-AMP") +
xlab("Prime type") +
#scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +
scale_colour_viridis_c(direction = -1) +
theme_classic() +
labs(colour = "Proportion of\ninfluence-aware\ntrials") +
scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1.00),
labels = c("(Negative) 0.00", "0.25", "0.50", "0.75", "(Positive) 1.00"),
limits = c(0, 1)) +
theme(legend.position = c(0.85, 0.30))
# Plot 2 - differences between influenced and non influenced trials
## add these probabilities back to the original data frame (omitting missing values)
predictions <- combined_trial_level_data %>%
dplyr::select(prime_type, influenced, unique_id,  experiment) %>%
na.omit %>%
mutate(prob = predict(model_2, type = c("response")),
`Influence of prime\non evaluation of target` = dplyr::recode(influenced,
"0" = "Uninfluenced trials",
"1" = "Influenced trials"),
prime_type = fct_relevel(prime_type, "Negative", "Positive"))
predictions <- combined_trial_level_data %>%
dplyr::select(prime_type, influenced, unique_id,  experiment) %>%
na.omit
## add these probabilities back to the original data frame (omitting missing values)
predictions <- combined_trial_level_data %>%
dplyr::select(prime_type, influenced, unique_id,  experiment) %>%
# na.omit %>%
mutate(prob = predict(model_2, type = c("response")),
`Influence of prime\non evaluation of target` = dplyr::recode(influenced,
"0" = "Uninfluenced trials",
"1" = "Influenced trials"),
prime_type = fct_relevel(prime_type, "Negative", "Positive"))
model_2 <- glmer(rating ~ prime_type * influenced + (1 | experiment/unique_id) + (1 | domain),
family = binomial(link = "logit"),
data = combined_trial_level_data)
save(model_2, file = "model_2.Rdata")
install.packages(c("lavaan", "semPlot", "semTools"))
# get data
combined_participant_level_data <- read.csv("data/combined_participant_level_data.csv")
combined_trial_level_data       <- read.csv("data/combined_trial_level_data.csv")
# get data
combined_participant_level_data <- read.csv("data/combined_participant_level_data.csv")
View(combined_participant_level_data)
# get data
combined_participant_level_data <- read.csv("data/combined_participant_level_data.csv") %>%
distinct(unique_id)
combined_participant_level_data %>%
distinct(unique_id) %>%
count()
combined_participant_level_data %>%
distinct(unique_id) %>%
dplyr::count()
