#                              data = .))) %>%
#     ungroup() %>%
#     dplyr::summarize(AUC_ci_lwr = round(quantile(x, 0.025, na.rm = TRUE), 3),
#                      AUC_ci_upr = round(quantile(x, 0.975, na.rm = TRUE), 3)) %>%
#     mutate(AUC_estimate = ruscios_A_results)
#
#   return(ruscios_A_boot_results)
# }
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv")
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
model_h1a <- glmer(correct ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data)
# model
model_h1a <- glmer(correct ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv")
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
model_h1a <- glmer(correct ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# plot
plot_model(model_h1a, type = "pred", terms = c("correct", "influenced"))
# plot
plot_model(model_h1a, type = "pred", terms = c("rating", "influenced"))
# plot
plot_model(model_h1a, type = "pred", terms = c("prime_type", "influenced"))
# plot
plot_model(model_h1a, type = "pred", terms = c("influenced", "prime_type"))
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"))
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"))
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# plot
plot_model(model_h1a, type = "pred", terms = c("influenced", "prime_type"))
tab_model(model_h1a, emph.p = FALSE, ci.hyphen = ", ")
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
model_h1a_predicted_effects <-
as.data.frame(effect("influenced:prime_type", model_h1a))
effect("influenced:prime_type", model_h1a)
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
model_h1a_predicted_effects <-
as.data.frame(effect("influenced:prime_type", model_h1a))
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = trial_level_ia_amp_data_exclusions)
# plot
plot_model(model_h1a, type = "pred", terms = c("influenced", "prime_type"))
model_h1a_predicted_effects <-
as.data.frame(effect("influenced:prime_type", model_h1a))
model_h1a
# model
fit_h2b <- lm(int_amp_effect ~ influence_rate,
data = task_level_data_exclusions)
View(task_level_data_exclusions)
# model
fit_h2b <- lm(IA_AMP_effect_positive_negative ~ influence_rate,
data = task_level_data_exclusions)
# plot
ggplot(subject_level_df, aes(influence_rate, IA_AMP_effect_positive_negative)) +
geom_point() +
geom_rug(position = "jitter") +
geom_smooth(method = lm) +
labs(title = "Experiment 1: Proportion of influenced trials and IA-AMP effect",
x = "Proportion of influenced trials",
y = "IA-AMP effect") +
theme_classic()
# plot
ggplot(task_level_data_exclusions, aes(influence_rate, IA_AMP_effect_positive_negative)) +
geom_point() +
geom_rug(position = "jitter") +
geom_smooth(method = lm) +
labs(title = "Experiment 1: Proportion of influenced trials and IA-AMP effect",
x = "Proportion of influenced trials",
y = "IA-AMP effect") +
theme_classic()
# plot
plot_model(fit_h2, type = "pred", terms = c("influence_rate"))
# plot
plot_model(fit_h2b, type = "pred", terms = c("influence_rate"))
# results table
tab_model(fit_h2b, emph.p = FALSE, ci.hyphen = ", ")
# plot
ggplot(task_level_data_exclusions, aes(influence_rate, IA_AMP_effect_positive_negative)) +
geom_point() +
geom_rug(position = "jitter") +
geom_smooth(method = lm) +
labs(title = "Experiment 1: Proportion of influenced trials and IA-AMP effect",
x = "Proportion of influenced trials",
y = "IA-AMP effect") +
theme_classic()
# Plot
ggplot(data = subject_level_df, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# plot
ggplot(task_level_data_exclusions, aes(influence_rate, IA_AMP_effect_positive_negative)) +
geom_point() +
geom_rug(position = "jitter") +
geom_smooth(method = lm) +
labs(title = "Proportion of influenced trials and IA-AMP effect",
x = "Proportion of influenced trials",
y = "IA-AMP effect") +
theme_classic()
# model
fit_h3 <- lm(influence_rate ~ influence_general, data = subject_level_df)
# Plot
ggplot(data = subject_level_df, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# table
sjt.lm(fit_h3, show.std = TRUE, digits.p = 15)
# Plot
ggplot(data = subject_level_df, aes(x = influence_general, y = influence_rate)) +
geom_jitter() +
geom_smooth(method = lm) +
geom_rug(position = "jitter") +
labs(x = "Offline influence (self report)", y = "Online influence (IA-AMP)") +
theme_classic()
# results table
tab_model(fit_h3, emph.p = FALSE, ci.hyphen = ", ")
# results table
tab_model(fit_h3, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# model
fit_h4 <- lm(int_amp_effect ~ influence_general + influence_rate, data = subject_level_df)
# plot
plot_model(fit_h4)
plot_model(fit_h4, type = "pred", terms = c("influence_general", "influence_rate"))
# results table
tab_model(fit_h4, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
plot_model(fit_h4, type = "pred", terms = c("influence_rate"))
plot_model(fit_h4, type = "pred", terms = c("influence_general"))
plot_model(fit_h4, type = "pred", terms = c("influence_rate"))
plot_model(fit_h4, type = "pred", terms = c("influence_general"))
temp <- trial_level_ia_amp_data_exclusions %>%
slice(1:1000)
# model
model_h1a <- glmer(rating ~ influenced * prime_type + (1 | subject),
family = binomial(link = "logit"),
data = temp)
# bootstrap estimates and CIs for key parameters
# apply fixef() to the output of each boot to get fixed effects, save only this to the data frame
model_h1a_int_boot <- bootMer(model_h1a,
FUN = fixef,
nsim = 1000,
parallel = "multicore")
# bootstrap estimates and CIs for key parameters
# apply fixef() to the output of each boot to get fixed effects, save only this to the data frame
model_h1a_int_boot <- bootMer(model_h1a,
FUN = fixef,
nsim = 100,
parallel = "multicore")
# model
fit_h3 <- lm(int_amp_effect ~ influence_general + influence_rate, data = subject_level_df)
# model performance
# add model predictions back to the original data frame
trial_level_ia_amp_data_exclusions$h3_predicted_probability <- predict(fit_h3, type = "response")
# predicted probability
h3_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "h3_predicted_probability",
group = "response")
h3_pp
ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "h3_predicted_probability",
group = "response")
View(trial_level_ia_amp_data_exclusions)
# predicted probability
h3_pp <- ruscios_A(data = trial_level_ia_amp_data_exclusions,
variable = "h3_predicted_probability",
group = "rating")
h3_pp
h3_pp
# functions
## Logistic model performance: probability of superiority
ruscios_A <- function(variable, group, data, value1 = 1, value2 = 0) {
# Ensure data is a data frame (e.g., not a tbl_data)
data <- as.data.frame(data)
# Select the observations for group 1
x <- data[data[[group]] == value1, variable]
# Select the observations for group 2
y <- data[data[[group]] == value2, variable]
# Matrix with difference between XY for all pairs (Guillaume Rousselet's suggestion)
m <- outer(x, y, FUN = "-")
# Convert to booleans; count ties as half true.
m <- ifelse(m == 0, 0.5, m > 0)
# Return proportion of TRUEs
ruscios_A <- round(mean(m), 3)
return(as.numeric(ruscios_A))
}
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
fit_h3 <- lm(int_amp_effect ~ influence_general + influence_rate, data = subject_level_df)
# model
fit_h3 <- lm(int_amp_effect ~ influence_general + influence_rate, data = task_level_data_exclusions)
# model
fit_h3 <- lm(IA_AMP_effect_positive_negative ~ influence_general + influence_rate,
data = task_level_data_exclusions)
# plot
plot_model(fit_h3, type = "pred", terms = c("influence_rate"))
plot_model(fit_h3, type = "pred", terms = c("influence_general"))
View(task_level_data_exclusions)
# functions
## Logistic model performance: probability of superiority
ruscios_A <- function(variable, group, data, value1 = 1, value2 = 0) {
# Ensure data is a data frame (e.g., not a tbl_data)
data <- as.data.frame(data)
# Select the observations for group 1
x <- data[data[[group]] == value1, variable]
# Select the observations for group 2
y <- data[data[[group]] == value2, variable]
# Matrix with difference between XY for all pairs (Guillaume Rousselet's suggestion)
m <- outer(x, y, FUN = "-")
# Convert to booleans; count ties as half true.
m <- ifelse(m == 0, 0.5, m > 0)
# Return proportion of TRUEs
ruscios_A <- round(mean(m), 3)
return(as.numeric(ruscios_A))
}
# get data
task_level_data <- read.csv("../data/processed/processed_data.csv")
trial_level_ia_amp_data <- read.csv("../data/processed/trial_level_ia_amp_positive_negative_data.csv") %>%
mutate(influenced = recode(influenced,
`0` = "no",
`1` = "yes"),
influenced = as.numeric(influenced))
# exclusions
task_level_data_exclusions <- task_level_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
trial_level_ia_amp_data_exclusions <- trial_level_ia_amp_data %>%
filter(self_exclusion_1 == "Yes, use my data" & complete_data == TRUE)
# model
fit_h3 <- lm(IA_AMP_effect_positive_negative ~ influence_general + influence_rate,
data = task_level_data_exclusions)
# plot
plot_model(fit_h3, type = "pred", terms = c("influence_rate"))
plot_model(fit_h3, type = "pred", terms = c("influence_general"))
# results table
tab_model(fit_h3, show.std = TRUE, emph.p = FALSE, ci.hyphen = ", ")
# plot
plot_model(fit_h3, type = "pred", terms = c("influence_rate"))
plot_model(fit_h3, type = "pred", terms = c("influence_general"))
task_level_data_exclusions %>%
distinct(influence_general)
questions_df    <- read.csv("raw/post_questions.csv")
self_report_data <- questions_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
select(subject, trialcode, response) %>%
group_by(subject) %>%
spread(trialcode, response) %>%
ungroup %>%
mutate(subject = as.character(subject))
complete_self_report_data <- self_report_data %>%
na.omit() %>%
distinct(subject)
View(complete_self_report_data)
complete_IA_AMP_data <- IA_AMP_data %>%
na.omit()
complete_self_report_data <- self_report_data %>%
na.omit()
View(complete_self_report_data)
self_report_data %>%
distinct(influence_general)
complete_self_report_data <- self_report_data %>%
na.omit()
complete_self_report_data %>%
distinct(influence_general)
complete_self_report_data %>%
count(influence_general)
complete_self_report_data %>%
count(influence_general)
complete_self_report_data %>%
distinct(influence_general)
complete_self_report_data %>%
dplyr::count(influence_general)
x <- complete_self_report_data %>%
dplyr::count(influence_general)
View(x)
allowed_response_options <- c("a few", "less than half", "none", "most", "about half", "more than half")
complete_self_report_data <- self_report_data %>%
#mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general)) %>%
na.omit() %>%
distinct(subject)
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general)) %>%
na.omit() %>%
distinct(subject)
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general)) %>%
na.omit() %>%
distinct(subject)
colnames(self_report_data)
self_report_data %>%
dplyr::count(awareness)
# some pilot data that used alternative reponse options made it into the data. exclude this.
allowed_response_options <- c("none", "a few", "less than half", "about half", "more than half", "most", "all")
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general)) %>%
na.omit() %>%
distinct(subject)
self_report_data %>%
dplyr::count(awareness)
colnames(self_report_data)
self_report_data %>%
dplyr::count(intentionality)
colnames(self_report_data)
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general),
intentionality    = ifelse(!(intentionality %in% allowed_response_options), NA, intentionality),
unintentionality  = ifelse(!(unintentionality %in% allowed_response_options), NA, unintentionality)) %>%
na.omit() %>%
distinct(subject)
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general),
intentionality    = ifelse(!(intentionality %in% allowed_response_options), NA, intentionality),
unintentionality  = ifelse(!(unintentionality %in% allowed_response_options), NA, unintentionality))
View(complete_self_report_data)
complete_self_report_data <- self_report_data %>%
mutate(influence_general = ifelse(!(influence_general %in% allowed_response_options), NA, influence_general),
intentionality    = ifelse(!(intentionality %in% allowed_response_options), NA, intentionality),
unintentionality  = ifelse(!(unintentionality %in% allowed_response_options), NA, unintentionality)) %>%
na.omit() %>%
distinct(subject)
complete_IA_AMP_data <- IA_AMP_data %>%
na.omit() %>%
distinct(subject)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# dependencies
library(tidyverse)
# get data
demographics_df <- read.csv("raw/demographics.csv")
IA_AMP_df       <- read.csv("raw/modified_intentionality_amp.csv")
questions_df    <- read.csv("raw/post_questions.csv")
# match Prolific IDs to subject numbers (for payment processing)
prolificid_df <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode == "ProlificCode") %>%
dplyr::select(subject, response)
demographics_data <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode != "ProlificCode") %>%
select(subject, trialcode, response) %>%
spread(trialcode, response) %>%
mutate(subject = as.character(subject))
self_report_data <- questions_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
select(subject, trialcode, response) %>%
group_by(subject) %>%
spread(trialcode, response) %>%
ungroup %>%
mutate(subject = as.character(subject))
IA_AMP_cleaned <- IA_AMP_df %>%
# reshape influence variable
mutate(influenced = as.numeric(as.character(lead(correct)))) %>%
# keep only test blocks and ratings trials
filter(!str_detect(trialcode, "intention_check"),
blockcode == "test") %>%
# mutate some vars
mutate(prime_type = ifelse(trialcode %in% c("prime_obama", "prime_positive"), "prime_type_A", "prime_type_B"),
subject = as.character(subject),
rating = as.numeric(as.character(correct))) %>%
# exclude participants without the right number of AMP trials
group_by(subject) %>%
filter(n() == 120) %>%
ungroup() %>%
select(subject, prime_type, rating, influenced) %>%
# exclude those who didn't have the right number of trials on the screener
mutate(subject = as.character(subject))
# score amp effect
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect) %>%
mutate(IA_AMP_effect_positive_negative = round(prime_type_A - prime_type_B, 2)) %>%
select(subject, IA_AMP_effect_positive_negative)
# dependencies
library(tidyverse)
# get data
demographics_df <- read.csv("raw/demographics.csv")
IA_AMP_df       <- read.csv("raw/modified_intentionality_amp.csv")
questions_df    <- read.csv("raw/post_questions.csv")
# match Prolific IDs to subject numbers (for payment processing)
prolificid_df <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode == "ProlificCode") %>%
dplyr::select(subject, response)
demographics_data <- demographics_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
filter(trialcode != "ProlificCode") %>%
select(subject, trialcode, response) %>%
spread(trialcode, response) %>%
mutate(subject = as.character(subject))
self_report_data <- questions_df %>%
distinct(subject, trialcode, .keep_all = TRUE) %>%
select(subject, trialcode, response) %>%
group_by(subject) %>%
spread(trialcode, response) %>%
ungroup %>%
mutate(subject = as.character(subject))
IA_AMP_cleaned <- IA_AMP_df %>%
# reshape influence variable
mutate(influenced = as.numeric(as.character(lead(correct)))) %>%
# keep only test blocks and ratings trials
filter(!str_detect(trialcode, "intention_check"),
blockcode == "test") %>%
# mutate some vars
mutate(prime_type = ifelse(trialcode %in% c("prime_obama", "prime_positive"), "prime_type_A", "prime_type_B"),
subject = as.character(subject),
rating = as.numeric(as.character(correct))) %>%
# exclude participants without the right number of AMP trials
group_by(subject) %>%
filter(n() == 120) %>%
ungroup() %>%
select(subject, prime_type, rating, influenced) %>%
# exclude those who didn't have the right number of trials on the screener
mutate(subject = as.character(subject))
# score amp effect
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect) %>%
mutate(IA_AMP_effect_positive_negative = round(prime_type_A - prime_type_B, 2)) %>%
select(subject, IA_AMP_effect_positive_negative)
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating))
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup() %>%
spread(prime_type, amp_effect)
IA_AMP_effect <- IA_AMP_cleaned %>%
group_by(subject, prime_type) %>%
summarize(amp_effect = mean(rating)) %>%
ungroup()
View(IA_AMP_effect)
View(IA_AMP_cleaned)
